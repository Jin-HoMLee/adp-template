{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f10547",
   "metadata": {},
   "source": [
    "# Chapter 1: Prompt Chaining (Hands-On Code Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b420faf",
   "metadata": {},
   "source": [
    "> Adapted and modified from https://docs.google.com/document/d/1flxKGrbnF2g8yh3F-oVD5Xx7ZumId56HbFpIiPdkqLI/edit?tab=t.0 \n",
    "> \n",
    "> Fr  5 Sep 2025 10:41:12 CEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40024e8",
   "metadata": {},
   "source": [
    "Implementing prompt chaining ranges from direct, sequential function calls within a script to the utilization of specialized frameworks designed to manage control flow, state, and component integration. Frameworks such as LangChain, LangGraph, Crew AI, and the Google Agent Development Kit (ADK) offer structured environments for constructing and executing these multi-step processes, which is particularly advantageous for complex architectures.\n",
    "\n",
    "For the purpose of demonstration, LangChain and LangGraph are suitable choices as their core APIs are explicitly designed for composing chains and graphs of operations. LangChain provides foundational abstractions for linear sequences, while LangGraph extends these capabilities to support stateful and cyclical computations, which are necessary for implementing more sophisticated agentic behaviors. This example will focus on a fundamental linear sequence.\n",
    "\n",
    "The following code implements a two-step prompt chain that functions as a data processing pipeline. The initial stage is designed to parse unstructured text and extract specific information. The subsequent stage then receives this extracted output and transforms it into a structured data format.\n",
    "\n",
    "To replicate this procedure, the required libraries must first be installed. This can be accomplished using the following command: \n",
    "\n",
    "```bash\n",
    "pip install langchain langchain-community langchain-openai langgraph\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e279296f",
   "metadata": {},
   "source": [
    "Note that langchain-openai can be substituted with the appropriate package for a different model provider. Subsequently, the execution environment must be configured with the necessary API credentials for the selected language model provider, such as OpenAI, Google Gemini, or Anthropic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65aff99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# For better security, load environment variables from a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Make sure your OPENAI_API_KEY is set in the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7e95320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Language Model (using ChatOpenAI is recommended)\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d5d1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prompt 1: Extract Information ---\n",
    "prompt_extract = ChatPromptTemplate.from_template(\n",
    "   \"Extract the technical specifications from the following text:\\n\\n{text_input}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b674bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prompt 2: Transform to JSON ---\n",
    "prompt_transform = ChatPromptTemplate.from_template(\n",
    "   \"Transform the following specifications into a JSON object with 'cpu', 'memory', and 'storage' as keys:\\n\\n{specifications}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b459c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build the Chain using LCEL ---\n",
    "# The StrOutputParser() converts the LLM's message output to a simple string.\n",
    "extraction_chain = prompt_extract | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "688c78b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full chain passes the output of the extraction chain into the 'specifications'\n",
    "# variable for the transformation prompt.\n",
    "full_chain = (\n",
    "   {\"specifications\": extraction_chain}\n",
    "   | prompt_transform\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da1ae31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run the Chain ---\n",
    "input_text = \"The new laptop model features a 3.5 GHz octa-core processor, 16GB of RAM, and a 1TB NVMe SSD.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8701bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the chain with the input text dictionary.\n",
    "final_result = full_chain.invoke({\"text_input\": input_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fe5ed13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final JSON Output ---\n",
      "{\n",
      "    \"cpu\": {\n",
      "        \"processor\": \"3.5 GHz octa-core\"\n",
      "    },\n",
      "    \"memory\": {\n",
      "        \"RAM\": \"16GB\"\n",
      "    },\n",
      "    \"storage\": {\n",
      "        \"Storage\": \"1TB NVMe SSD\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Final JSON Output ---\")\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfd6a51",
   "metadata": {},
   "source": [
    "This Python code demonstrates how to use the LangChain library to process text. It utilizes two separate prompts: one to extract technical specifications from an input string and another to format these specifications into a JSON object. The ChatOpenAI model is employed for language model interactions, and the StrOutputParser ensures the output is in a usable string format. The LangChain Expression Language (LCEL) is used to elegantly chain these prompts and the language model together. The first chain, extraction_chain, extracts the specifications. The full_chain then takes the output of the extraction and uses it as input for the transformation prompt. A sample input text describing a laptop is provided. The full_chain is invoked with this text, processing it through both steps. The final result, a JSON string containing the extracted and formatted specifications, is then printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a99c5a",
   "metadata": {},
   "source": [
    "## Experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19938b1a",
   "metadata": {},
   "source": [
    "Above, only an `extraction_chain` was built and used in the `full_chain`. \n",
    "\n",
    "Here, we try to additionally build and use a `transformation_chain`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4fbb900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final JSON Output ---\n",
      "{\n",
      "    \"cpu\": \"\",\n",
      "    \"memory\": \"\",\n",
      "    \"storage\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --- Build the Chain using LCEL ---\n",
    "# The StrOutputParser() converts the LLM's message output to a simple string.\n",
    "transformation_chain = prompt_transform | llm | StrOutputParser()\n",
    "\n",
    "# The full chain passes the output of the extraction chain into the 'specifications'\n",
    "# variable for the transformation prompt.\n",
    "full_chain = (\n",
    "   {\"specifications\": extraction_chain}\n",
    "   | transformation_chain\n",
    ")\n",
    "\n",
    "# Execute the chain with the input text dictionary.\n",
    "final_result = full_chain.invoke({\"text_input\": input_text})\n",
    "print(\"\\n--- Final JSON Output ---\")\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24518356",
   "metadata": {},
   "source": [
    "```\n",
    "--- Final JSON Output ---\n",
    "{\n",
    "    \"cpu\": {\n",
    "        \"processor\": \"3.5 GHz octa-core\"\n",
    "    },\n",
    "    \"memory\": {\n",
    "        \"RAM\": \"16GB\"\n",
    "    },\n",
    "    \"storage\": {\n",
    "        \"Storage\": \"1TB NVMe SSD\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b62e3",
   "metadata": {},
   "source": [
    "This works.\n",
    "\n",
    "Further, we test if we can use something like `{\"text_input\": input_text}` at the beginning of the `full_chain`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7601345e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# The full chain passes the output of the extraction chain into the 'specifications'\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# variable for the transformation prompt.\u001b[39;00m\n\u001b[32m      3\u001b[39m full_chain = (\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m    \u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext_input\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m   \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspecifications\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mextraction_chain\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m   \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformation_chain\u001b[49m\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/adp-01-prompt-chaining/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3046\u001b[39m, in \u001b[36mRunnableSequence.__ror__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   3035\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, RunnableSequence):\n\u001b[32m   3036\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m RunnableSequence(\n\u001b[32m   3037\u001b[39m         other.first,\n\u001b[32m   3038\u001b[39m         *other.middle,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3043\u001b[39m         name=other.name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m   3044\u001b[39m     )\n\u001b[32m   3045\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m RunnableSequence(\n\u001b[32m-> \u001b[39m\u001b[32m3046\u001b[39m     \u001b[43mcoerce_to_runnable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   3047\u001b[39m     \u001b[38;5;28mself\u001b[39m.first,\n\u001b[32m   3048\u001b[39m     *\u001b[38;5;28mself\u001b[39m.middle,\n\u001b[32m   3049\u001b[39m     \u001b[38;5;28mself\u001b[39m.last,\n\u001b[32m   3050\u001b[39m     name=\u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m   3051\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/adp-01-prompt-chaining/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5994\u001b[39m, in \u001b[36mcoerce_to_runnable\u001b[39m\u001b[34m(thing)\u001b[39m\n\u001b[32m   5992\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m RunnableLambda(cast(\u001b[33m\"\u001b[39m\u001b[33mCallable[[Input], Output]\u001b[39m\u001b[33m\"\u001b[39m, thing))\n\u001b[32m   5993\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(thing, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m5994\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mRunnable[Input, Output]\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mRunnableParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthing\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   5995\u001b[39m msg = (\n\u001b[32m   5996\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected a Runnable, callable or dict.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   5997\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInstead got an unsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(thing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   5998\u001b[39m )\n\u001b[32m   5999\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/adp-01-prompt-chaining/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3616\u001b[39m, in \u001b[36mRunnableParallel.__init__\u001b[39m\u001b[34m(self, steps__, **kwargs)\u001b[39m\n\u001b[32m   3613\u001b[39m merged = {**steps__} \u001b[38;5;28;01mif\u001b[39;00m steps__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m   3614\u001b[39m merged.update(kwargs)\n\u001b[32m   3615\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m-> \u001b[39m\u001b[32m3616\u001b[39m     steps__={key: \u001b[43mcoerce_to_runnable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, r \u001b[38;5;129;01min\u001b[39;00m merged.items()}\n\u001b[32m   3617\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/adp-01-prompt-chaining/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5999\u001b[39m, in \u001b[36mcoerce_to_runnable\u001b[39m\u001b[34m(thing)\u001b[39m\n\u001b[32m   5994\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mRunnable[Input, Output]\u001b[39m\u001b[33m\"\u001b[39m, RunnableParallel(thing))\n\u001b[32m   5995\u001b[39m msg = (\n\u001b[32m   5996\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected a Runnable, callable or dict.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   5997\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInstead got an unsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(thing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   5998\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m5999\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[31mTypeError\u001b[39m: Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# The full chain passes the output of the extraction chain into the 'specifications'\n",
    "# variable for the transformation prompt.\n",
    "full_chain = (\n",
    "   {\"text_input\": input_text}\n",
    "   | {\"specifications\": extraction_chain}\n",
    "   | transformation_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1fedf5",
   "metadata": {},
   "source": [
    "The error tells us that the chain cannot handle simple strings but only \"Runnable, callable or dict\". \n",
    "\n",
    "Let's try, if we can scrape some text from the web and use it with our prompt chain: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f92f8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   Brand  \\n                                                    \\u200eLenovo     Product Dimensions  \\n                                                    \\u200e32.43 x 21.38 x 1.79 cm; 1.37 kg     Batteries  \\n                                                    \\u200e1 Lithium Polymer batteries required. (included)     Item model number  \\n                                                    \\u200e83EQ005UUK     Manufacturer  \\n                                                    \\u200eLenovo     Series  \\n                                                    \\u200eIdeaPad Slim 3 14IAH8     Colour\\n  \\n                                                    \\u200eAbyss Blue     Form Factor  \\n                                                    \\u200eUltra-Portable     Standing screen display size  \\n                                                    \\u200e14 Inches     Screen Resolution  \\n                                                    \\u200e1920 x 1080 pixels     Resolution  \\n                                                    \\u200e1920x1080     Processor Brand  \\n                                                    \\u200eIntel     Processor Type  \\n                                                    \\u200eCore i5     Processor Speed  \\n                                                    \\u200e4.4 GHz     Processor Count  \\n                                                    \\u200e8     Memory Technology  \\n                                                    \\u200eLpddr 5     Computer Memory Type  \\n                                                    \\u200eDDR5 RAM     Maximum Memory Supported  \\n                                                    \\u200e16 GB     Hard Drive Size  \\n                                                    \\u200e512 GB     Hard Disk Description  \\n                                                    \\u200eSSD     Hard Drive Interface  \\n                                                    \\u200eSerial ATA     Audio Details\\n  \\n                                                    \\u200einternal     Speaker Description  \\n                                                    \\u200eDolby Audio     Graphics Chipset Brand  \\n                                                    \\u200eIntel     Graphics Card Description  \\n                                                    \\u200eIntegrated     Graphics RAM Type  \\n                                                    \\u200eShared     Graphics Card Interface  \\n                                                    \\u200ePCI-Express x4     Connectivity Type  \\n                                                    \\u200eBluetooth, Wi-Fi     Wireless Type  \\n                                                    \\u200e802.11ax, Bluetooth     Number of USB 3.0 Ports  \\n                                                    \\u200e2     Number of HDMI Ports  \\n                                                    \\u200e1     Operating System  \\n                                                    \\u200eWindows 11 Home     Average Battery Life (in hours)  \\n                                                    \\u200e2 Hours     Are Batteries Included  \\n                                                    \\u200eYes     Lithium Battery Energy Content  \\n                                                    \\u200e47 Watt Hours     Lithium Battery Packaging  \\n                                                    \\u200eBatteries contained in equipment     Number Of Lithium Ion Cells  \\n                                                    \\u200e1     Item Weight  \\n                                                    \\u200e1.37 kg     Guaranteed software updates until  \\n                                                    \\u200eunknown   '"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install selenium and webdriver-manager if you haven't already (works with selenium==4.35.0 and webdriver-manager==4.0.2)\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "url = \"https://www.amazon.co.uk/Lenovo-IdeaPad-Laptop-i5-12450H-Windows/dp/B0D7MLLWJ8/ref=sr_1_1?dib=eyJ2IjoiMSJ9.PbYBW-5-7rUuuHRHA3lYyBas94074aaRbm9FhL9mrAFq-dLy_dYZ0zpFJiOa82rLiD6dzx0-eN0sIrf8JULowVjUG0hkP1zKVEo0g1j-lbjCmYtsKlfhW5fohsnG4X__qFiDk_JtVz0_Hb8BWgVx0cq1lxXCmAGupUrwFUFzcPvA0qZFr-RHY66nBgsI28HGVcFKiCPevuLVQ3hOrcME15871kpnEDpU4JAxETlF0TDENPmaY85fsatNdl5y9lMuVD35SyL6V0Bp5AXn5Gj8bFhfWjChxIJVze_VpPf53tg.mGdnjIgfeP8Swo5h0FxGXZpFwWyCDW_tQiwOb3BwOe8&dib_tag=se&keywords=lenovo%2Blaptop&qid=1757064468&s=computers&sr=1-1&th=1\"\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')  # Run in headless mode (no browser UI)\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "# Try to find the product information section\n",
    "input_id = \"productDetails_techSpec_section_1\"\n",
    "product_info_html = soup.find(id=input_id)\n",
    "\n",
    "product_info_text = product_info_html.get_text()\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "product_info_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb410d48",
   "metadata": {},
   "source": [
    "The `product_info_text` is quite raw, but let's just try if the llm can handle it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5e9a2ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final JSON Output ---\n",
      "{\n",
      "    \"cpu\": {\n",
      "        \"brand\": \"Intel\",\n",
      "        \"type\": \"Core i5\",\n",
      "        \"speed\": \"4.4 GHz\",\n",
      "        \"count\": 8\n",
      "    },\n",
      "    \"memory\": {\n",
      "        \"technology\": \"Lpddr 5\",\n",
      "        \"type\": \"DDR5 RAM\",\n",
      "        \"max_supported\": \"16 GB\"\n",
      "    },\n",
      "    \"storage\": {\n",
      "        \"size\": \"512 GB\",\n",
      "        \"description\": \"SSD\",\n",
      "        \"interface\": \"Serial ATA\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "input_text = product_info_text\n",
    "\n",
    "# Execute the chain with the input text dictionary.\n",
    "final_result = full_chain.invoke({\"text_input\": input_text})\n",
    "print(\"\\n--- Final JSON Output ---\")\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66fb7ec",
   "metadata": {},
   "source": [
    "Looks like it did a quite good job. \n",
    "\n",
    "Here is a screenshot of the actual webpage, where you can verify the correct output of our prompt chain: \n",
    "\n",
    "![Amazon Product Details](images/amazon-product-details.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3010a13",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
